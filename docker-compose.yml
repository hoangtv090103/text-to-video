services:
  redis:
    image: redis:7-alpine
    container_name: text-to-video-redis
    ports:
      - "6379:6379"
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 3s
      retries: 3
    restart: unless-stopped
    networks:
      - text-to-video-network

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: text-to-video-frontend
    ports:
      - "3000:3000"
    environment:
      - NEXT_PUBLIC_API_URL=http://server:8000
    depends_on:
      - server
    restart: unless-stopped
    networks:
      - text-to-video-network

  server:
    build:
      context: ./server
      dockerfile: Dockerfile
    container_name: text-to-video-server
    ports:
      - "8000:8000"
    environment:
      - LLM_URL=${LLM_URL}
      - LLM_API_KEY=${LLM_API_KEY}
      - LLM_MODEL=${LLM_MODEL}
      - LLM_PROVIDER=${LLM_PROVIDER:-openai}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-3.5-turbo}
      - GOOGLE_API_KEY=${GOOGLE_API_KEY}
      - GOOGLE_MODEL=${GOOGLE_MODEL:-gemini-pro}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - ANTHROPIC_MODEL=${ANTHROPIC_MODEL:-claude-3-sonnet-20240229}
      - HUGGINGFACE_MODEL=${HUGGINGFACE_MODEL:-google/flan-t5-base}
      - HUGGINGFACE_API_KEY=${HUGGINGFACE_API_KEY}
      - LOCAL_MODEL_PATH=${LOCAL_MODEL_PATH:-llama2}
      - LOCAL_MODEL_TYPE=${LOCAL_MODEL_TYPE:-llama}
      - LOG_LEVEL=info
      - TTS_SERVICE_URL=http://chatterbox-tts:4123/v1/audio/speech
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_DB=0
      - ASSET_STORAGE_PATH=/app/data/assets
      - VIDEO_OUTPUT_PATH=/app/data/videos
      - VISUAL_STORAGE_PATH=/app/data/visuals
      - MAX_CONCURRENT_JOBS=5
      - MAX_CONCURRENT_SCENES=10
    volumes:
      - ./server/data:/app/data
      - ./server/voice-sample.mp3:/app/voice-sample.mp3:ro
    depends_on:
      - redis
      - chatterbox-tts
    restart: unless-stopped
    networks:
      - text-to-video-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  chatterbox-tts:
    build:
      context: ./chatterbox-tts-api
      dockerfile: docker/Dockerfile
    container_name: chatterbox-tts-api
    ports:
      - "4123:4123"
    environment:
      - PORT=4123
      - HOST=0.0.0.0
      - EXAGGERATION=0.5
      - CFG_WEIGHT=0.5
      - TEMPERATURE=0.7
      - MAX_CHUNK_LENGTH=250
      - MAX_TOTAL_LENGTH=2500
      - VOICE_SAMPLE_PATH=/app/voice-sample.mp3
      - DEVICE=cpu
      - MODEL_CACHE_DIR=/cache
      - VOICE_LIBRARY_DIR=/voices
      - MEMORY_CLEANUP_INTERVAL=3
      - CUDA_CACHE_CLEAR_INTERVAL=2
      - ENABLE_MEMORY_MONITORING=true
      - OMP_NUM_THREADS=8
      - MKL_NUM_THREADS=8
      - TORCH_NUM_THREADS=8
      - OPENBLAS_NUM_THREADS=8
      - VECLIB_MAXIMUM_THREADS=8
      - TORCH_CUDNN_V8_API_ENABLED=1
      - PYTORCH_ENABLE_MPS_FALLBACK=1
      - HF_HUB_DISABLE_TELEMETRY=1
      - TRANSFORMERS_OFFLINE=0
      - HF_HUB_CACHE=/cache/huggingface
    volumes:
      - ./voice-sample.mp3:/app/voice-sample.mp3:ro
      - chatterbox-models:/cache
      - chatterbox-voices:/voices
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4123/health"]
      interval: 45s
      timeout: 15s
      retries: 5
      start_period: 10m
    networks:
      - text-to-video-network

volumes:
  redis_data:
  chatterbox-models:
  chatterbox-voices:

networks:
  text-to-video-network:
    driver: bridge
